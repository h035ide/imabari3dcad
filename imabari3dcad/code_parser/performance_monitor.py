"""
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ChromaDBã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¶™ç¶šçš„ã«ç›£è¦–ã—ã€
å•é¡Œã‚’æ—©æœŸç™ºè¦‹ã™ã‚‹ãŸã‚ã®ã‚¢ãƒ©ãƒ¼ãƒˆæ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚
"""

import time
import json
import statistics
from typing import Dict, Any, List, Optional, Callable
from dataclasses import dataclass, asdict
from collections import deque
from pathlib import Path
import threading
import logging


@dataclass
class PerformanceSnapshot:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ"""
    timestamp: float
    operation_type: str  # 'search', 'insert', 'filter'
    response_time: float  # ç§’
    collection_size: int
    success: bool
    additional_metrics: Dict[str, Any] = None

    def __post_init__(self):
        if self.additional_metrics is None:
            self.additional_metrics = {}


@dataclass
class AlertRule:
    """ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«"""
    name: str
    condition: str  # æ¡ä»¶å¼ï¼ˆä¾‹: "avg_response_time > 1.0"ï¼‰
    threshold_value: float
    evaluation_window: int  # è©•ä¾¡ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆç§’ï¼‰
    severity: str  # 'Critical', 'Warning', 'Info'
    enabled: bool = True
    cooldown_period: int = 300  # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æœŸé–“ï¼ˆç§’ï¼‰


@dataclass
class Alert:
    """ã‚¢ãƒ©ãƒ¼ãƒˆ"""
    rule_name: str
    message: str
    severity: str
    timestamp: float
    current_value: float
    threshold_value: float
    additional_data: Dict[str, Any] = None

    def __post_init__(self):
        if self.additional_data is None:
            self.additional_data = {}


class ChromaDBPerformanceMonitor:
    """ChromaDBã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, 
                 collection=None,
                 history_size: int = 1000,
                 alert_callback: Optional[Callable[[Alert], None]] = None):
        """
        ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã®åˆæœŸåŒ–
        
        Args:
            collection: ChromaDBã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            history_size: ä¿æŒã™ã‚‹å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®æœ€å¤§æ•°
            alert_callback: ã‚¢ãƒ©ãƒ¼ãƒˆç™ºç”Ÿæ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
        """
        self.collection = collection
        self.history_size = history_size
        self.alert_callback = alert_callback or self._default_alert_callback
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å±¥æ­´ï¼ˆå›ºå®šã‚µã‚¤ã‚ºã‚­ãƒ¥ãƒ¼ï¼‰
        self.performance_history = deque(maxlen=history_size)
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«
        self.alert_rules = {}
        self._setup_default_alert_rules()
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆå±¥æ­´ã¨ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ç®¡ç†
        self.alert_history = deque(maxlen=100)
        self.last_alert_times = {}
        
        # çµ±è¨ˆæƒ…å ±
        self.statistics_cache = {}
        self.cache_expiry = 0
        self.cache_duration = 60  # 1åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        
        # ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
        self.logger = logging.getLogger(__name__)
        
        # ç›£è¦–çŠ¶æ…‹
        self.monitoring_active = False
        self.monitoring_thread = None

    def _setup_default_alert_rules(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«ã‚’è¨­å®š"""
        default_rules = [
            AlertRule(
                name="é«˜ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“",
                condition="avg_response_time > threshold",
                threshold_value=1.0,
                evaluation_window=300,
                severity="Warning"
            ),
            AlertRule(
                name="æ¥µã‚ã¦é«˜ã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“",
                condition="avg_response_time > threshold",
                threshold_value=3.0,
                evaluation_window=60,
                severity="Critical"
            ),
            AlertRule(
                name="ä½æˆåŠŸç‡",
                condition="success_rate < threshold",
                threshold_value=0.95,
                evaluation_window=300,
                severity="Warning"
            ),
            AlertRule(
                name="æ¥µã‚ã¦ä½ã„æˆåŠŸç‡",
                condition="success_rate < threshold",
                threshold_value=0.80,
                evaluation_window=60,
                severity="Critical"
            ),
            AlertRule(
                name="æ¤œç´¢ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŠ£åŒ–",
                condition="search_avg_time > threshold",
                threshold_value=0.5,
                evaluation_window=600,
                severity="Warning"
            ),
            AlertRule(
                name="æŒ¿å…¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŠ£åŒ–",
                condition="insert_avg_time > threshold",
                threshold_value=2.0,
                evaluation_window=600,
                severity="Warning"
            )
        ]
        
        for rule in default_rules:
            self.alert_rules[rule.name] = rule

    def record_performance(self, 
                         operation_type: str,
                         response_time: float,
                         success: bool = True,
                         additional_metrics: Dict[str, Any] = None):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’è¨˜éŒ²"""
        try:
            collection_size = self.collection.count() if self.collection else 0
        except:
            collection_size = 0
        
        snapshot = PerformanceSnapshot(
            timestamp=time.time(),
            operation_type=operation_type,
            response_time=response_time,
            collection_size=collection_size,
            success=success,
            additional_metrics=additional_metrics or {}
        )
        
        self.performance_history.append(snapshot)
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ï¼ˆæ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãŒè¿½åŠ ã•ã‚ŒãŸãŸã‚ï¼‰
        self._clear_statistics_cache()
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
        self._check_alerts()

    def get_current_statistics(self, time_window: int = 300) -> Dict[str, Any]:
        """ç¾åœ¨ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        current_time = time.time()
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        if (current_time < self.cache_expiry and 
            f"stats_{time_window}" in self.statistics_cache):
            return self.statistics_cache[f"stats_{time_window}"]
        
        # æŒ‡å®šæ™‚é–“çª“å†…ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        cutoff_time = current_time - time_window
        recent_data = [
            snapshot for snapshot in self.performance_history
            if snapshot.timestamp >= cutoff_time
        ]
        
        if not recent_data:
            return {"error": "ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™"}
        
        # çµ±è¨ˆè¨ˆç®—
        stats = self._calculate_statistics(recent_data)
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        self.statistics_cache[f"stats_{time_window}"] = stats
        self.cache_expiry = current_time + self.cache_duration
        
        return stats

    def _calculate_statistics(self, data: List[PerformanceSnapshot]) -> Dict[str, Any]:
        """çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—"""
        if not data:
            return {}
        
        # åŸºæœ¬çµ±è¨ˆ
        response_times = [d.response_time for d in data]
        successes = [d.success for d in data]
        
        stats = {
            "data_points": len(data),
            "time_range": {
                "start": min(d.timestamp for d in data),
                "end": max(d.timestamp for d in data)
            },
            "response_time": {
                "avg": statistics.mean(response_times),
                "median": statistics.median(response_times),
                "min": min(response_times),
                "max": max(response_times),
                "std_dev": statistics.stdev(response_times) if len(response_times) > 1 else 0
            },
            "success_rate": sum(successes) / len(successes),
            "operations_per_second": len(data) / (max(d.timestamp for d in data) - min(d.timestamp for d in data))
        }
        
        # æ“ä½œã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ
        operation_stats = {}
        for op_type in set(d.operation_type for d in data):
            op_data = [d for d in data if d.operation_type == op_type]
            if op_data:
                op_times = [d.response_time for d in op_data]
                op_successes = [d.success for d in op_data]
                
                operation_stats[op_type] = {
                    "count": len(op_data),
                    "avg_time": statistics.mean(op_times),
                    "success_rate": sum(op_successes) / len(op_successes)
                }
        
        stats["by_operation"] = operation_stats
        
        return stats

    def add_alert_rule(self, rule: AlertRule):
        """ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«ã‚’è¿½åŠ """
        self.alert_rules[rule.name] = rule
        self.logger.info(f"ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«è¿½åŠ : {rule.name}")

    def remove_alert_rule(self, rule_name: str):
        """ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«ã‚’å‰Šé™¤"""
        if rule_name in self.alert_rules:
            del self.alert_rules[rule_name]
            self.logger.info(f"ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«å‰Šé™¤: {rule_name}")

    def _check_alerts(self):
        """ã‚¢ãƒ©ãƒ¼ãƒˆæ¡ä»¶ã‚’ãƒã‚§ãƒƒã‚¯"""
        current_time = time.time()
        
        for rule_name, rule in self.alert_rules.items():
            if not rule.enabled:
                continue
            
            # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãƒã‚§ãƒƒã‚¯
            if rule_name in self.last_alert_times:
                if current_time - self.last_alert_times[rule_name] < rule.cooldown_period:
                    continue
            
            # ã‚¢ãƒ©ãƒ¼ãƒˆæ¡ä»¶è©•ä¾¡
            if self._evaluate_alert_condition(rule):
                alert = self._create_alert(rule)
                self._trigger_alert(alert)
                self.last_alert_times[rule_name] = current_time

    def _evaluate_alert_condition(self, rule: AlertRule) -> bool:
        """ã‚¢ãƒ©ãƒ¼ãƒˆæ¡ä»¶ã‚’è©•ä¾¡"""
        try:
            stats = self.get_current_statistics(rule.evaluation_window)
            
            if "error" in stats:
                return False
            
            # æ¡ä»¶ã«å¿œã˜ãŸè©•ä¾¡
            if "avg_response_time" in rule.condition:
                current_value = stats["response_time"]["avg"]
                return current_value > rule.threshold_value
            
            elif "success_rate" in rule.condition:
                current_value = stats["success_rate"]
                return current_value < rule.threshold_value
            
            elif "search_avg_time" in rule.condition:
                search_stats = stats["by_operation"].get("search", {})
                if search_stats:
                    current_value = search_stats["avg_time"]
                    return current_value > rule.threshold_value
            
            elif "insert_avg_time" in rule.condition:
                insert_stats = stats["by_operation"].get("insert", {})
                if insert_stats:
                    current_value = insert_stats["avg_time"]
                    return current_value > rule.threshold_value
            
            return False
            
        except Exception as e:
            self.logger.error(f"ã‚¢ãƒ©ãƒ¼ãƒˆæ¡ä»¶è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False

    def _create_alert(self, rule: AlertRule) -> Alert:
        """ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ä½œæˆ"""
        stats = self.get_current_statistics(rule.evaluation_window)
        
        # ç¾åœ¨å€¤ã‚’å–å¾—
        current_value = 0.0
        if "avg_response_time" in rule.condition:
            current_value = stats["response_time"]["avg"]
        elif "success_rate" in rule.condition:
            current_value = stats["success_rate"]
        elif "search_avg_time" in rule.condition:
            search_stats = stats["by_operation"].get("search", {})
            current_value = search_stats.get("avg_time", 0.0)
        elif "insert_avg_time" in rule.condition:
            insert_stats = stats["by_operation"].get("insert", {})
            current_value = insert_stats.get("avg_time", 0.0)
        
        message = f"{rule.name}: ç¾åœ¨å€¤ {current_value:.3f}, é–¾å€¤ {rule.threshold_value}"
        
        return Alert(
            rule_name=rule.name,
            message=message,
            severity=rule.severity,
            timestamp=time.time(),
            current_value=current_value,
            threshold_value=rule.threshold_value,
            additional_data={"stats": stats}
        )

    def _trigger_alert(self, alert: Alert):
        """ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ç™ºç«"""
        self.alert_history.append(alert)
        self.logger.warning(f"ã‚¢ãƒ©ãƒ¼ãƒˆç™ºç”Ÿ: {alert.message}")
        
        try:
            self.alert_callback(alert)
        except Exception as e:
            self.logger.error(f"ã‚¢ãƒ©ãƒ¼ãƒˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {str(e)}")

    def _default_alert_callback(self, alert: Alert):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¢ãƒ©ãƒ¼ãƒˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        severity_symbol = {
            "Critical": "ğŸš¨",
            "Warning": "âš ï¸", 
            "Info": "â„¹ï¸"
        }.get(alert.severity, "ğŸ“¢")
        
        print(f"{severity_symbol} {alert.severity}: {alert.message}")

    def get_alert_history(self, hours: int = 24) -> List[Alert]:
        """ã‚¢ãƒ©ãƒ¼ãƒˆå±¥æ­´ã‚’å–å¾—"""
        cutoff_time = time.time() - (hours * 3600)
        return [
            alert for alert in self.alert_history
            if alert.timestamp >= cutoff_time
        ]

    def analyze_trends(self, time_window: int = 3600) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æ"""
        current_time = time.time()
        
        # ç¾åœ¨ã¨éå»ã®çµ±è¨ˆã‚’æ¯”è¼ƒ
        current_stats = self.get_current_statistics(time_window // 2)
        past_cutoff = current_time - time_window
        mid_cutoff = current_time - (time_window // 2)
        
        past_data = [
            snapshot for snapshot in self.performance_history
            if past_cutoff <= snapshot.timestamp < mid_cutoff
        ]
        
        if not past_data or "error" in current_stats:
            return {"error": "ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã«ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"}
        
        past_stats = self._calculate_statistics(past_data)
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—
        trends = {}
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã®ãƒˆãƒ¬ãƒ³ãƒ‰
        current_avg = current_stats["response_time"]["avg"]
        past_avg = past_stats["response_time"]["avg"]
        time_trend = "æ”¹å–„" if current_avg < past_avg else "æ‚ªåŒ–"
        time_change_pct = ((current_avg - past_avg) / past_avg) * 100
        
        trends["response_time"] = {
            "direction": time_trend,
            "change_percent": time_change_pct,
            "current": current_avg,
            "past": past_avg
        }
        
        # æˆåŠŸç‡ã®ãƒˆãƒ¬ãƒ³ãƒ‰
        current_success = current_stats["success_rate"]
        past_success = past_stats["success_rate"]
        success_trend = "æ”¹å–„" if current_success > past_success else "æ‚ªåŒ–"
        success_change_pct = ((current_success - past_success) / past_success) * 100
        
        trends["success_rate"] = {
            "direction": success_trend,
            "change_percent": success_change_pct,
            "current": current_success,
            "past": past_success
        }
        
        # ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®ãƒˆãƒ¬ãƒ³ãƒ‰
        current_throughput = current_stats["operations_per_second"]
        past_throughput = past_stats["operations_per_second"]
        throughput_trend = "æ”¹å–„" if current_throughput > past_throughput else "æ‚ªåŒ–"
        throughput_change_pct = ((current_throughput - past_throughput) / past_throughput) * 100
        
        trends["throughput"] = {
            "direction": throughput_trend,
            "change_percent": throughput_change_pct,
            "current": current_throughput,
            "past": past_throughput
        }
        
        return {
            "analysis_window": time_window,
            "trends": trends,
            "recommendation": self._generate_trend_recommendations(trends)
        }

    def _generate_trend_recommendations(self, trends: Dict[str, Any]) -> List[str]:
        """ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã«åŸºã¥ãæ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ"""
        recommendations = []
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã®æ‚ªåŒ–
        if trends["response_time"]["direction"] == "æ‚ªåŒ–":
            if abs(trends["response_time"]["change_percent"]) > 20:
                recommendations.append("ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ãŒå¤§å¹…ã«æ‚ªåŒ–ã—ã¦ã„ã¾ã™ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æœ€é©åŒ–ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
            else:
                recommendations.append("ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ãŒæ‚ªåŒ–å‚¾å‘ã«ã‚ã‚Šã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ è² è·ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        # æˆåŠŸç‡ã®æ‚ªåŒ–
        if trends["success_rate"]["direction"] == "æ‚ªåŒ–":
            recommendations.append("æˆåŠŸç‡ãŒä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ç¢ºèªã—ã€éšœå®³ã®åŸå› ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚")
        
        # ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®æ‚ªåŒ–
        if trends["throughput"]["direction"] == "æ‚ªåŒ–":
            if abs(trends["throughput"]["change_percent"]) > 30:
                recommendations.append("ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãŒå¤§å¹…ã«ä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ã®å¢—å¼·ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
        
        if not recommendations:
            recommendations.append("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯å®‰å®šã—ã¦ã„ã¾ã™ã€‚")
        
        return recommendations

    def _clear_statistics_cache(self):
        """çµ±è¨ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        self.statistics_cache.clear()
        self.cache_expiry = 0

    def export_monitoring_report(self, output_path: str = None) -> str:
        """ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        if output_path is None:
            timestamp = int(time.time())
            output_path = f"performance_monitoring_report_{timestamp}.json"
        
        # ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        report_data = {
            "timestamp": time.time(),
            "collection_info": {
                "name": getattr(self.collection, 'name', 'unknown'),
                "size": self.collection.count() if self.collection else 0
            },
            "current_statistics": self.get_current_statistics(),
            "trend_analysis": self.analyze_trends(),
            "alert_rules": {name: asdict(rule) for name, rule in self.alert_rules.items()},
            "recent_alerts": [asdict(alert) for alert in self.get_alert_history()],
            "performance_summary": {
                "total_data_points": len(self.performance_history),
                "monitoring_duration_hours": (
                    (max(d.timestamp for d in self.performance_history) - 
                     min(d.timestamp for d in self.performance_history)) / 3600
                ) if self.performance_history else 0
            }
        }
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        print(f"ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆã‚’ {output_path} ã«ä¿å­˜ã—ã¾ã—ãŸ")
        return output_path

    def start_continuous_monitoring(self, interval: int = 60):
        """ç¶™ç¶šçš„ãªç›£è¦–ã‚’é–‹å§‹"""
        if self.monitoring_active:
            print("ç›£è¦–ã¯æ—¢ã«é–‹å§‹ã•ã‚Œã¦ã„ã¾ã™")
            return
        
        self.monitoring_active = True
        
        def monitoring_loop():
            while self.monitoring_active:
                try:
                    # å®šæœŸçš„ãªçµ±è¨ˆæ›´æ–°ã¨ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
                    self.get_current_statistics()
                    time.sleep(interval)
                except Exception as e:
                    self.logger.error(f"ç›£è¦–ãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    time.sleep(10)
        
        self.monitoring_thread = threading.Thread(target=monitoring_loop, daemon=True)
        self.monitoring_thread.start()
        
        print(f"ç¶™ç¶šç›£è¦–ã‚’é–‹å§‹ã—ã¾ã—ãŸï¼ˆé–“éš”: {interval}ç§’ï¼‰")

    def stop_continuous_monitoring(self):
        """ç¶™ç¶šçš„ãªç›£è¦–ã‚’åœæ­¢"""
        self.monitoring_active = False
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=5)
        print("ç¶™ç¶šç›£è¦–ã‚’åœæ­¢ã—ã¾ã—ãŸ")


# ä½¿ç”¨ä¾‹ã®ãƒ‡ãƒ¢é–¢æ•°
def demo_monitor():
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã®ãƒ‡ãƒ¢"""
    print("ChromaDBãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã®ãƒ‡ãƒ¢")
    
    # ãƒ¢ãƒƒã‚¯ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
    class MockCollection:
        def __init__(self):
            self.name = "demo_collection"
            self._count = 1000
        
        def count(self):
            return self._count
    
    # ãƒ‡ãƒ¢å®Ÿè¡Œ
    mock_collection = MockCollection()
    monitor = ChromaDBPerformanceMonitor(mock_collection)
    
    print("\n1. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã®è¨˜éŒ²")
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®è¨˜éŒ²
    import random
    for i in range(20):
        response_time = random.uniform(0.1, 2.0)
        success = random.random() > 0.05  # 95%æˆåŠŸç‡
        operation = random.choice(["search", "insert", "filter"])
        
        monitor.record_performance(operation, response_time, success)
    
    print(f"è¨˜éŒ²ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ: {len(monitor.performance_history)}")
    
    print("\n2. çµ±è¨ˆæƒ…å ±ã®å–å¾—")
    stats = monitor.get_current_statistics()
    print(f"å¹³å‡ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“: {stats['response_time']['avg']:.3f}ç§’")
    print(f"æˆåŠŸç‡: {stats['success_rate']*100:.1f}%")
    
    print("\n3. ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆ")
    # é«˜ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    monitor.record_performance("search", 5.0, True)  # é–¾å€¤è¶…é
    
    print("\n4. ã‚¢ãƒ©ãƒ¼ãƒˆå±¥æ­´")
    alerts = monitor.get_alert_history()
    print(f"ã‚¢ãƒ©ãƒ¼ãƒˆæ•°: {len(alerts)}")
    
    for alert in alerts[-3:]:  # æœ€æ–°3ä»¶
        print(f"- {alert.severity}: {alert.message}")
    
    print("\n5. ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ")
    trends = monitor.analyze_trends()
    if "error" not in trends:
        for metric, trend_data in trends["trends"].items():
            print(f"{metric}: {trend_data['direction']} ({trend_data['change_percent']:+.1f}%)")
    
    print("\n6. ãƒ¬ãƒãƒ¼ãƒˆã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    report_path = monitor.export_monitoring_report()
    print(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {report_path}")


if __name__ == "__main__":
    demo_monitor()
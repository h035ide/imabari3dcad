"""
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹æ€§ã®åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯Pythonã‚³ãƒ¼ãƒ‰ã®æ™‚é–“è¨ˆç®—é‡ã€ç©ºé–“è¨ˆç®—é‡ã€
ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã€æœ€é©åŒ–ææ¡ˆã‚’åˆ†æã—ã¾ã™ã€‚
"""

import ast
import re
import time
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from pathlib import Path


@dataclass
class PerformanceMetrics:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    time_complexity: str  # æ™‚é–“è¨ˆç®—é‡ (ä¾‹: O(n), O(n^2))
    space_complexity: str  # ç©ºé–“è¨ˆç®—é‡
    bottlenecks: List[str]  # ãƒœãƒˆãƒ«ãƒãƒƒã‚¯
    optimizations: List[str]  # æœ€é©åŒ–ææ¡ˆ
    memory_usage_estimate: str  # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æ¨å®š
    performance_score: float  # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢ (0-1)


class PerformanceAnalyzer:
    """ã‚³ãƒ¼ãƒ‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹æ€§ã‚’åˆ†æã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®šç¾©
        self.complexity_patterns = {
            # åŸºæœ¬çš„ãªãƒ«ãƒ¼ãƒ—ãƒ‘ã‚¿ãƒ¼ãƒ³
            'single_loop': {'pattern': r'for\s+\w+\s+in', 'complexity': 'O(n)'},
            'nested_loop': {'pattern': r'for\s+\w+\s+in.*?for\s+\w+\s+in', 'complexity': 'O(nÂ²)'},
            'triple_loop': {'pattern': r'(for\s+\w+\s+in.*?){3,}', 'complexity': 'O(nÂ³)'},
            
            # ä¸€èˆ¬çš„ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ‘ã‚¿ãƒ¼ãƒ³
            'sort': {'pattern': r'\.sort\(\)|sorted\(', 'complexity': 'O(n log n)'},
            'dict_lookup': {'pattern': r'\[.*?\]|\\.get\(', 'complexity': 'O(1)'},
            'list_append': {'pattern': r'\.append\(', 'complexity': 'O(1)'},
            'list_extend': {'pattern': r'\.extend\(', 'complexity': 'O(k)'},
            
            # æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³
            'linear_search': {'pattern': r'\s+in\s+\w+', 'complexity': 'O(n)'},
            'recursive': {'pattern': r'def\s+\w+.*?:\s*.*?\w+\(', 'complexity': 'O(2^n)'},
        }
        
        # ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.bottleneck_patterns = {
            'file_io': r'open\(|\.read\(\)|\.write\(',
            'network_io': r'requests\.|urllib\.|socket\.',
            'database_query': r'\.execute\(|\.query\(',
            'large_list_creation': r'\[.*for.*in.*\]',
            'string_concatenation': r'\+.*["\']',
            'global_access': r'global\s+\w+',
            'exception_handling': r'try:.*except',
        }
        
        # æœ€é©åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.optimization_suggestions = {
            'list_comprehension': {
                'pattern': r'for\s+\w+\s+in.*?\.append\(',
                'suggestion': 'ãƒªã‚¹ãƒˆå†…åŒ…è¡¨è¨˜ã‚’ä½¿ç”¨ã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ”¹å–„'
            },
            'generator_expression': {
                'pattern': r'\[.*for.*in.*\]',
                'suggestion': 'ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿å¼ã‚’ä½¿ç”¨ã—ã¦ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å‰Šæ¸›'
            },
            'set_membership': {
                'pattern': r'\s+in\s+\[.*\]',
                'suggestion': 'ãƒªã‚¹ãƒˆã§ã¯ãªãsetã‚’ä½¿ç”¨ã—ã¦æ¤œç´¢ã‚’é«˜é€ŸåŒ–'
            },
            'string_join': {
                'pattern': r'\+.*["\']',
                'suggestion': 'str.join()ã‚’ä½¿ç”¨ã—ã¦æ–‡å­—åˆ—çµåˆã‚’æœ€é©åŒ–'
            },
            'cache_results': {
                'pattern': r'def\s+\w+.*?return',
                'suggestion': '@lru_cacheãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã‚’æ¤œè¨'
            }
        }

    def analyze_code(self, code: str, function_name: str = "") -> PerformanceMetrics:
        """
        ã‚³ãƒ¼ãƒ‰ã®åŒ…æ‹¬çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
        
        Args:
            code: åˆ†æå¯¾è±¡ã®ã‚³ãƒ¼ãƒ‰
            function_name: é–¢æ•°åï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        
        Returns:
            PerformanceMetrics: åˆ†æçµæœ
        """
        try:
            # å„ç¨®åˆ†æã®å®Ÿè¡Œ
            time_complexity = self.analyze_time_complexity(code)
            space_complexity = self.analyze_space_complexity(code)
            bottlenecks = self.identify_bottlenecks(code)
            optimizations = self.suggest_optimizations(code)
            memory_estimate = self.estimate_memory_usage(code)
            score = self.calculate_performance_score(code)
            
            return PerformanceMetrics(
                time_complexity=time_complexity,
                space_complexity=space_complexity,
                bottlenecks=bottlenecks,
                optimizations=optimizations,
                memory_usage_estimate=memory_estimate,
                performance_score=score
            )
            
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return PerformanceMetrics(
                time_complexity="åˆ†æã‚¨ãƒ©ãƒ¼",
                space_complexity="åˆ†æã‚¨ãƒ©ãƒ¼",
                bottlenecks=[f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}"],
                optimizations=[],
                memory_usage_estimate="ä¸æ˜",
                performance_score=0.0
            )

    def analyze_time_complexity(self, code: str) -> str:
        """æ™‚é–“è¨ˆç®—é‡ã‚’åˆ†æ"""
        # è¤‡é›‘åº¦ã®åˆæœŸå€¤
        max_complexity = "O(1)"
        
        # å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
        for pattern_name, pattern_info in self.complexity_patterns.items():
            if re.search(pattern_info['pattern'], code, re.DOTALL | re.IGNORECASE):
                current_complexity = pattern_info['complexity']
                # ã‚ˆã‚Šé«˜ã„è¤‡é›‘åº¦ã‚’æ¡ç”¨
                if self._is_higher_complexity(current_complexity, max_complexity):
                    max_complexity = current_complexity
        
        # ãƒã‚¹ãƒˆã—ãŸãƒ«ãƒ¼ãƒ—ã®ç‰¹åˆ¥ãªå‡¦ç†
        nested_loops = self._count_nested_loops(code)
        if nested_loops > 1:
            max_complexity = f"O(n^{nested_loops})"
        
        return max_complexity

    def analyze_space_complexity(self, code: str) -> str:
        """ç©ºé–“è¨ˆç®—é‡ã‚’åˆ†æ"""
        # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ä½¿ç”¨ã‚’ãƒã‚§ãƒƒã‚¯
        space_indicators = {
            r'list\(|append\(|extend\(': 'O(n)',
            r'dict\(|{.*}': 'O(n)',
            r'set\(': 'O(n)',
            r'range\(': 'O(1)',
            r'yield': 'O(1)',  # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿
        }
        
        max_space = "O(1)"
        
        for pattern, complexity in space_indicators.items():
            if re.search(pattern, code):
                if self._is_higher_complexity(complexity, max_space):
                    max_space = complexity
        
        # å†å¸°é–¢æ•°ã®å ´åˆ
        if re.search(r'def\s+\w+.*?:\s*.*?\w+\(.*?\)', code, re.DOTALL):
            max_space = "O(n) (å†å¸°ã‚¹ã‚¿ãƒƒã‚¯)"
        
        return max_space

    def identify_bottlenecks(self, code: str) -> List[str]:
        """ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’ç‰¹å®š"""
        bottlenecks = []
        
        for bottleneck_type, pattern in self.bottleneck_patterns.items():
            if re.search(pattern, code):
                bottleneck_msg = self._get_bottleneck_message(bottleneck_type)
                bottlenecks.append(bottleneck_msg)
        
        # ãƒã‚¹ãƒˆã—ãŸãƒ«ãƒ¼ãƒ—ã®ãƒã‚§ãƒƒã‚¯
        nested_count = self._count_nested_loops(code)
        if nested_count >= 3:
            bottlenecks.append(f"æ·±ã„ãƒã‚¹ãƒˆãƒ«ãƒ¼ãƒ— (ãƒ¬ãƒ™ãƒ« {nested_count}) - è¨ˆç®—æ™‚é–“ãŒå¤§å¹…ã«å¢—åŠ ")
        
        # å¤§ããªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ä½œæˆ
        if re.search(r'\[.*for.*in.*for.*in.*\]', code):
            bottlenecks.append("ãƒã‚¹ãƒˆã—ãŸãƒªã‚¹ãƒˆå†…åŒ…è¡¨è¨˜ - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¤§ãã„")
        
        return bottlenecks

    def suggest_optimizations(self, code: str) -> List[str]:
        """æœ€é©åŒ–ææ¡ˆã‚’ç”Ÿæˆ"""
        optimizations = []
        
        for opt_type, opt_info in self.optimization_suggestions.items():
            if re.search(opt_info['pattern'], code):
                optimizations.append(opt_info['suggestion'])
        
        # ç‰¹åˆ¥ãªæœ€é©åŒ–ææ¡ˆ
        if re.search(r'for.*in.*range\(len\(', code):
            optimizations.append("enumerate()ã‚’ä½¿ç”¨ã—ã¦ã‚ˆã‚Šèª­ã¿ã‚„ã™ãåŠ¹ç‡çš„ã«")
        
        if re.search(r'if.*and.*or', code):
            optimizations.append("æ¡ä»¶å¼ã‚’åˆ†å‰²ã—ã¦çŸ­çµ¡è©•ä¾¡ã‚’æ´»ç”¨")
        
        if re.search(r'\.sort\(\).*\.reverse\(\)', code):
            optimizations.append("sort(reverse=True)ã‚’ä½¿ç”¨ã—ã¦ä¸€åº¦ã§ã‚½ãƒ¼ãƒˆ")
        
        return optimizations

    def estimate_memory_usage(self, code: str) -> str:
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æ¨å®š"""
        # åŸºæœ¬çš„ãªãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æ¨å®š
        memory_factors = []
        
        # ãƒªã‚¹ãƒˆã®ä½œæˆ
        if re.search(r'\[.*for.*in.*\]', code):
            memory_factors.append("ãƒªã‚¹ãƒˆå†…åŒ…è¡¨è¨˜: O(n)ãƒ¡ãƒ¢ãƒª")
        
        # è¾æ›¸ã®ä½œæˆ
        if re.search(r'{.*for.*in.*}', code):
            memory_factors.append("è¾æ›¸å†…åŒ…è¡¨è¨˜: O(n)ãƒ¡ãƒ¢ãƒª")
        
        # å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        if re.search(r'\.read\(\)|\.readlines\(\)', code):
            memory_factors.append("ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“èª­ã¿è¾¼ã¿: ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç›¸å½“")
        
        # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã®ä½¿ç”¨
        if re.search(r'yield|generator', code):
            memory_factors.append("ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ä½¿ç”¨: O(1)ãƒ¡ãƒ¢ãƒª (åŠ¹ç‡çš„)")
        
        if not memory_factors:
            return "æœ€å°é™ (O(1))"
        
        return " / ".join(memory_factors)

    def calculate_performance_score(self, code: str) -> float:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®— (0-1ã®ç¯„å›²)"""
        score = 1.0
        
        # æ™‚é–“è¨ˆç®—é‡ã«ã‚ˆã‚‹ãƒšãƒŠãƒ«ãƒ†ã‚£
        complexity = self.analyze_time_complexity(code)
        if "n^3" in complexity or "2^n" in complexity:
            score -= 0.4
        elif "n^2" in complexity:
            score -= 0.3
        elif "n log n" in complexity:
            score -= 0.1
        
        # ãƒœãƒˆãƒ«ãƒãƒƒã‚¯æ•°ã«ã‚ˆã‚‹ãƒšãƒŠãƒ«ãƒ†ã‚£
        bottleneck_count = len(self.identify_bottlenecks(code))
        score -= bottleneck_count * 0.1
        
        # æœ€é©åŒ–å¯èƒ½æ•°ã«ã‚ˆã‚‹ãƒšãƒŠãƒ«ãƒ†ã‚£
        optimization_count = len(self.suggest_optimizations(code))
        score -= optimization_count * 0.05
        
        # è‰¯ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒœãƒ¼ãƒŠã‚¹
        if re.search(r'yield|generator', code):
            score += 0.1  # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ä½¿ç”¨
        
        if re.search(r'@lru_cache|@cache', code):
            score += 0.1  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨
        
        return max(0.0, min(1.0, score))

    def _count_nested_loops(self, code: str) -> int:
        """ãƒã‚¹ãƒˆã—ãŸãƒ«ãƒ¼ãƒ—ã®æ·±ã•ã‚’æ•°ãˆã‚‹"""
        try:
            tree = ast.parse(code)
            max_depth = 0
            
            def count_loop_depth(node, current_depth=0):
                nonlocal max_depth
                
                if isinstance(node, (ast.For, ast.While)):
                    current_depth += 1
                    max_depth = max(max_depth, current_depth)
                
                for child in ast.iter_child_nodes(node):
                    count_loop_depth(child, current_depth)
            
            count_loop_depth(tree)
            return max_depth
            
        except:
            # ASTè§£æã«å¤±æ•—ã—ãŸå ´åˆã¯æ­£è¦è¡¨ç¾ã§æ¨å®š
            nested_pattern = r'for\s+\w+\s+in.*?for\s+\w+\s+in'
            if re.search(nested_pattern, code, re.DOTALL):
                return 2
            return 1 if re.search(r'for\s+\w+\s+in', code) else 0

    def _is_higher_complexity(self, complexity1: str, complexity2: str) -> bool:
        """è¨ˆç®—é‡ã®å¤§å°ã‚’æ¯”è¼ƒ"""
        complexity_order = [
            "O(1)", "O(log n)", "O(n)", "O(n log n)", 
            "O(nÂ²)", "O(n^2)", "O(nÂ³)", "O(n^3)", "O(2^n)"
        ]
        
        try:
            index1 = complexity_order.index(complexity1)
            index2 = complexity_order.index(complexity2)
            return index1 > index2
        except ValueError:
            return False

    def _get_bottleneck_message(self, bottleneck_type: str) -> str:
        """ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—"""
        messages = {
            'file_io': "ãƒ•ã‚¡ã‚¤ãƒ«I/Oæ“ä½œ - å‡¦ç†æ™‚é–“ã®å¤§éƒ¨åˆ†ã‚’å ã‚ã‚‹å¯èƒ½æ€§",
            'network_io': "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯I/Oæ“ä½œ - é€šä¿¡é…å»¶ã®å½±éŸ¿ã‚’å—ã‘ã‚‹",
            'database_query': "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒª - ã‚¯ã‚¨ãƒªæœ€é©åŒ–ã‚’æ¤œè¨",
            'large_list_creation': "å¤§ããªãƒªã‚¹ãƒˆä½œæˆ - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã¨GCã®è² è·",
            'string_concatenation': "æ–‡å­—åˆ—çµåˆ - join()ã®ä½¿ç”¨ã‚’æ¤œè¨",
            'global_access': "ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‚¢ã‚¯ã‚»ã‚¹ - ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°ã®ä½¿ç”¨ã‚’æ¤œè¨",
            'exception_handling': "ä¾‹å¤–å‡¦ç† - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰",
        }
        return messages.get(bottleneck_type, f"æ¤œå‡ºã•ã‚ŒãŸãƒœãƒˆãƒ«ãƒãƒƒã‚¯: {bottleneck_type}")

    def analyze_file(self, file_path: str) -> Dict[str, PerformanceMetrics]:
        """ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # é–¢æ•°ã”ã¨ã«åˆ†æ
            tree = ast.parse(content)
            results = {}
            
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    func_code = ast.get_source_segment(content, node)
                    if func_code:
                        results[node.name] = self.analyze_code(func_code, node.name)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã®åˆ†æ
            results['__file_overall__'] = self.analyze_code(content, "ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“")
            
            return results
            
        except Exception as e:
            return {
                'error': PerformanceMetrics(
                    time_complexity="åˆ†æã‚¨ãƒ©ãƒ¼",
                    space_complexity="åˆ†æã‚¨ãƒ©ãƒ¼", 
                    bottlenecks=[f"ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"],
                    optimizations=[],
                    memory_usage_estimate="ä¸æ˜",
                    performance_score=0.0
                )
            }

    def generate_report(self, metrics: PerformanceMetrics, function_name: str = "") -> str:
        """åˆ†æçµæœã®ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report = []
        
        if function_name:
            report.append(f"## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãƒ¬ãƒãƒ¼ãƒˆ: {function_name}")
        else:
            report.append("## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        
        report.append("")
        report.append(f"**ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢**: {metrics.performance_score:.2f}/1.0")
        report.append(f"**æ™‚é–“è¨ˆç®—é‡**: {metrics.time_complexity}")
        report.append(f"**ç©ºé–“è¨ˆç®—é‡**: {metrics.space_complexity}")
        report.append(f"**ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¨å®š**: {metrics.memory_usage_estimate}")
        report.append("")
        
        if metrics.bottlenecks:
            report.append("### ğŸš¨ æ¤œå‡ºã•ã‚ŒãŸãƒœãƒˆãƒ«ãƒãƒƒã‚¯")
            for bottleneck in metrics.bottlenecks:
                report.append(f"- {bottleneck}")
            report.append("")
        
        if metrics.optimizations:
            report.append("### ğŸ’¡ æœ€é©åŒ–ææ¡ˆ")
            for optimization in metrics.optimizations:
                report.append(f"- {optimization}")
            report.append("")
        
        return "\n".join(report)


# ä½¿ç”¨ä¾‹ã®ãƒ‡ãƒ¢é–¢æ•°
def demo_analysis():
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã®ãƒ‡ãƒ¢"""
    analyzer = PerformanceAnalyzer()
    
    # ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰
    sample_codes = {
        "åŠ¹ç‡çš„ãªã‚³ãƒ¼ãƒ‰": """
def find_max(numbers):
    if not numbers:
        return None
    return max(numbers)
        """,
        
        "éåŠ¹ç‡ãªã‚³ãƒ¼ãƒ‰": """
def find_duplicates(data):
    duplicates = []
    for i in range(len(data)):
        for j in range(len(data)):
            if i != j and data[i] == data[j]:
                if data[i] not in duplicates:
                    duplicates.append(data[i])
    return duplicates
        """,
        
        "æœ€é©åŒ–ãŒå¿…è¦ãªã‚³ãƒ¼ãƒ‰": """
def process_data(items):
    result = ""
    for item in items:
        result = result + str(item) + ","
    return result[:-1]
        """
    }
    
    print("=== ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãƒ‡ãƒ¢ ===")
    for name, code in sample_codes.items():
        print(f"\n{name}:")
        metrics = analyzer.analyze_code(code, name)
        print(analyzer.generate_report(metrics, name))


if __name__ == "__main__":
    demo_analysis()
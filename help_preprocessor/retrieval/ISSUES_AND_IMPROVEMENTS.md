# Help Preprocessor Retrieval System - æ”¹å–„ç‚¹ã¨å•é¡Œç‚¹ã®ç²¾æŸ»

## ğŸ” **å®Ÿæ–½ã—ãŸç²¾æŸ»å†…å®¹**

### **1. ã‚³ãƒ¼ãƒ‰å“è³ªç²¾æŸ»**
- **Ruffé™çš„è§£æ**: 15å€‹ã®ã‚³ãƒ¼ãƒ‰å“è³ªå•é¡Œã‚’æ¤œå‡ºãƒ»ä¿®æ­£
- **å‹ãƒ’ãƒ³ãƒˆ**: æœªå®šç¾©å‹å‚ç…§ã®ä¿®æ­£
- **ã‚¤ãƒ³ãƒãƒ¼ãƒˆæœ€é©åŒ–**: æœªä½¿ç”¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®å‰Šé™¤

### **2. ä¾å­˜é–¢ä¿‚åˆ†æ**
- **LangChain**: v0.3.27 (æ­£å¸¸)
- **OpenAI**: v1.107.0 (æ­£å¸¸)
- **NumPy**: v2.2.6 (æ­£å¸¸)
- **scikit-learn**: æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« (TF-IDFæ©Ÿèƒ½ã§å¿…è¦)

### **3. çµ±åˆãƒ†ã‚¹ãƒˆ**
- **ã‚·ã‚¹ãƒ†ãƒ ä½œæˆ**: æ­£å¸¸
- **åŸºæœ¬ã‚¤ãƒ³ãƒãƒ¼ãƒˆ**: æ­£å¸¸
- **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿**: æ­£å¸¸

### **4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡**
- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**: è»½é‡ (18.6MB)
- **ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ**: é«˜é€Ÿ (1000å›/0.0ms)

## ğŸš¨ **ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œç‚¹**

### **1. é‡è¦åº¦: é«˜ - ä¾å­˜é–¢ä¿‚ã®å•é¡Œ**

#### **scikit-learn æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**
```python
# å•é¡Œ: TF-IDFæ©Ÿèƒ½ã§å¿…è¦ã ãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
from sklearn.feature_extraction.text import TfidfVectorizer  # ImportError
```

**å½±éŸ¿**: ç–ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ãŒä½¿ç”¨ä¸å¯

**å¯¾ç­–**:
```bash
uv pip install scikit-learn
```

#### **LlamaIndex ãƒãƒ¼ã‚¸ãƒ§ãƒ³äº’æ›æ€§**
```python
# å•é¡Œ: __version__ å±æ€§ãŒãªã„
llama_index.__version__  # AttributeError
```

**å½±éŸ¿**: ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ¤œè¨¼ä¸å¯

**å¯¾ç­–**: ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ¤œè¨¼ãƒ­ã‚¸ãƒƒã‚¯ã®æ”¹å–„

### **2. é‡è¦åº¦: ä¸­ - è¨­è¨ˆä¸Šã®èª²é¡Œ**

#### **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ä¸€è²«æ€§ä¸è¶³**
```python
# å•é¡Œä¾‹: ä¸€éƒ¨ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãŒä¸ååˆ†
try:
    results = retriever.search(context)
except Exception as exc:
    logging.warning("Search failed: %s", exc)  # å…·ä½“çš„ã§ãªã„
    return []  # ç©ºçµæœã‚’è¿”ã™ãŒã€åŸå› ãŒä¸æ˜
```

**å½±éŸ¿**: ãƒ‡ãƒãƒƒã‚°å›°é›£ã€é‹ç”¨æ™‚ã®å•é¡Œç‰¹å®šãŒå›°é›£

#### **è¨­å®šæ¤œè¨¼ã®ä¸è¶³**
```python
# å•é¡Œ: ç„¡åŠ¹ãªè¨­å®šå€¤ã®ãƒã‚§ãƒƒã‚¯ä¸è¶³
HybridRetrieverConfig(
    enable_dense=True,
    chroma_config=None  # Noneã ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¦ã„ã‚‹
)
```

**å½±éŸ¿**: å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼ã®å¯èƒ½æ€§

### **3. é‡è¦åº¦: ä¸­ - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹èª²é¡Œ**

#### **åŒæœŸå‡¦ç†ã®åˆ¶é™**
```python
# å•é¡Œ: ä¸¦åˆ—æ¤œç´¢ãŒå®Ÿéš›ã«ã¯é †æ¬¡å®Ÿè¡Œ
for name, retriever in active_retrievers.items():
    results = retriever.search(context)  # é †æ¬¡å®Ÿè¡Œ
```

**å½±éŸ¿**: æ¤œç´¢é€Ÿåº¦ã®åˆ¶é™

#### **ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®èª²é¡Œ**
```python
# å•é¡Œ: å…¨çµæœã‚’ãƒ¡ãƒ¢ãƒªã«ä¿æŒ
all_results = []
for retriever in retrievers:
    all_results.extend(retriever.search())  # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å¢—åŠ 
```

**å½±éŸ¿**: å¤§é‡ãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ¡ãƒ¢ãƒªä¸è¶³

### **4. é‡è¦åº¦: ä½ - ä½¿ã„ã‚„ã™ã•ã®èª²é¡Œ**

#### **è¨­å®šã®è¤‡é›‘ã•**
- å¤šæ•°ã®è¨­å®šé …ç›® (20+ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)
- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®å¦¥å½“æ€§æ¤œè¨¼ä¸è¶³
- è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä¾‹ãŒé™å®šçš„

#### **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä¸æ•´åˆ**
- ä¸€éƒ¨ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚·ã‚°ãƒãƒãƒ£ãŒå®Ÿè£…ã¨ç•°ãªã‚‹
- ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè‹±èªã¨æ—¥æœ¬èªæ··åœ¨

## ğŸ”§ **å…·ä½“çš„ãªæ”¹å–„ææ¡ˆ**

### **1. å³åº§ã«å¯¾å¿œã™ã¹ãæ”¹å–„ (å„ªå…ˆåº¦: é«˜)**

#### **A. ä¾å­˜é–¢ä¿‚ã®å®Œå…¨åŒ–**
```bash
# requirements.txt ã«è¿½åŠ 
scikit-learn>=1.3.0
whoosh>=2.7.4
elasticsearch>=8.0.0  # ã‚ªãƒ—ã‚·ãƒ§ãƒ³
```

#### **B. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®æ¨™æº–åŒ–**
```python
class RetrievalError(Exception):
    """Base exception for retrieval operations."""
    pass

class ConfigurationError(RetrievalError):
    """Configuration validation error."""
    pass

class SearchError(RetrievalError):
    """Search operation error."""
    pass

def safe_search(self, context: QueryContext) -> List[SearchResult]:
    """Safe search with standardized error handling."""
    try:
        return self._execute_search(context)
    except ConfigurationError:
        raise  # Re-raise configuration errors
    except Exception as exc:
        raise SearchError(f"Search failed for {self.get_name()}: {exc}") from exc
```

#### **C. è¨­å®šæ¤œè¨¼ã®å¼·åŒ–**
```python
def validate_config(self) -> List[str]:
    """Validate configuration and return error messages."""
    errors = []
    
    if self.enable_dense and not self.chroma_config:
        errors.append("Dense search enabled but chroma_config is None")
    
    if self.enable_sparse and not (self.tfidf_config or self.bm25_config):
        errors.append("Sparse search enabled but no sparse config provided")
        
    return errors
```

### **2. ä¸­æœŸçš„ãªæ”¹å–„ (å„ªå…ˆåº¦: ä¸­)**

#### **A. çœŸã®ä¸¦åˆ—å‡¦ç†**
```python
import asyncio
import concurrent.futures

async def parallel_search(self, context: QueryContext) -> Dict[str, List[SearchResult]]:
    """Execute searches in parallel."""
    loop = asyncio.get_event_loop()
    
    tasks = []
    for name, retriever in self.retrievers.items():
        task = loop.run_in_executor(
            None, 
            retriever.search, 
            context
        )
        tasks.append((name, task))
    
    results = {}
    for name, task in tasks:
        try:
            results[name] = await task
        except Exception as exc:
            logging.warning("Parallel search failed for %s: %s", name, exc)
            results[name] = []
    
    return results
```

#### **B. ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®æ”¹å–„**
```python
def stream_search_results(self, context: QueryContext) -> Iterator[SearchResult]:
    """Stream results to reduce memory usage."""
    for name, retriever in self.retrievers.items():
        try:
            for result in retriever.search(context):
                yield result
        except Exception as exc:
            logging.warning("Stream search failed for %s: %s", name, exc)
            continue

def fuse_streaming_results(
    self, 
    result_streams: List[Iterator[SearchResult]], 
    context: QueryContext
) -> Iterator[SearchResult]:
    """Fuse results from multiple streams."""
    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œã®çµæœçµ±åˆå®Ÿè£…
    pass
```

#### **C. ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ã®è¿½åŠ **
```python
from functools import lru_cache
import hashlib

class CachedRetriever(BaseRetriever):
    def __init__(self, base_retriever: BaseRetriever, cache_size: int = 128):
        self.base_retriever = base_retriever
        self.cache_size = cache_size
    
    @lru_cache(maxsize=128)
    def _cached_search(self, query_hash: str, context_str: str) -> List[SearchResult]:
        """Cached search implementation."""
        context = QueryContext.from_string(context_str)
        return self.base_retriever.search(context)
    
    def search(self, context: QueryContext) -> List[SearchResult]:
        query_hash = hashlib.md5(context.query.encode()).hexdigest()
        context_str = context.to_string()
        return self._cached_search(query_hash, context_str)
```

### **3. é•·æœŸçš„ãªæ”¹å–„ (å„ªå…ˆåº¦: ä½)**

#### **A. ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**
```python
class RetrievalPlugin(ABC):
    @abstractmethod
    def get_name(self) -> str:
        pass
    
    @abstractmethod
    def search(self, context: QueryContext) -> List[SearchResult]:
        pass
    
    @abstractmethod
    def get_config_schema(self) -> Dict[str, Any]:
        pass

class PluginManager:
    def __init__(self):
        self.plugins: Dict[str, RetrievalPlugin] = {}
    
    def register_plugin(self, plugin: RetrievalPlugin):
        self.plugins[plugin.get_name()] = plugin
    
    def get_plugin(self, name: str) -> Optional[RetrievalPlugin]:
        return self.plugins.get(name)
```

#### **B. è©³ç´°ãªç›£è¦–ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹**
```python
from dataclasses import dataclass
from typing import Dict
import time

@dataclass
class SearchMetrics:
    query: str
    retriever_name: str
    execution_time: float
    result_count: int
    memory_usage: int
    error: Optional[str] = None

class MetricsCollector:
    def __init__(self):
        self.metrics: List[SearchMetrics] = []
    
    def record_search(self, query: str, retriever_name: str, 
                     execution_time: float, result_count: int, 
                     memory_usage: int, error: Optional[str] = None):
        metric = SearchMetrics(
            query=query,
            retriever_name=retriever_name,
            execution_time=execution_time,
            result_count=result_count,
            memory_usage=memory_usage,
            error=error
        )
        self.metrics.append(metric)
    
    def get_performance_report(self) -> Dict[str, Any]:
        """Generate performance analysis report."""
        if not self.metrics:
            return {}
        
        total_queries = len(self.metrics)
        avg_time = sum(m.execution_time for m in self.metrics) / total_queries
        error_rate = len([m for m in self.metrics if m.error]) / total_queries
        
        return {
            "total_queries": total_queries,
            "average_execution_time": avg_time,
            "error_rate": error_rate,
            "retriever_performance": self._analyze_by_retriever()
        }
```

## ğŸ›¡ï¸ **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è€ƒæ…®äº‹é …**

### **1. å…¥åŠ›æ¤œè¨¼**
```python
def validate_query(query: str) -> str:
    """Validate and sanitize user query."""
    if not query or not query.strip():
        raise ValueError("Query cannot be empty")
    
    # é•·ã•åˆ¶é™
    if len(query) > 10000:
        raise ValueError("Query too long")
    
    # å±é™ºãªãƒ‘ã‚¿ãƒ¼ãƒ³ã®é™¤å»
    import re
    # SQL ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–
    dangerous_patterns = [r"--", r";", r"DROP", r"DELETE", r"INSERT"]
    for pattern in dangerous_patterns:
        if re.search(pattern, query, re.IGNORECASE):
            raise ValueError(f"Dangerous pattern detected: {pattern}")
    
    return query.strip()
```

### **2. èªè¨¼ãƒ»èªå¯**
```python
class AuthenticatedRetriever:
    def __init__(self, base_retriever: BaseRetriever, auth_handler):
        self.base_retriever = base_retriever
        self.auth_handler = auth_handler
    
    def search(self, context: QueryContext, user_token: str) -> List[SearchResult]:
        """Authenticated search with access control."""
        user = self.auth_handler.validate_token(user_token)
        if not user:
            raise PermissionError("Invalid authentication token")
        
        # ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡
        if not self.auth_handler.can_search(user, context.query):
            raise PermissionError("Insufficient permissions for this query")
        
        results = self.base_retriever.search(context)
        
        # çµæœãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        filtered_results = []
        for result in results:
            if self.auth_handler.can_access(user, result):
                filtered_results.append(result)
        
        return filtered_results
```

## ğŸ“Š **æ¨å¥¨å®Ÿè£…é †åº**

### **Phase 1: ç·Šæ€¥å¯¾å¿œ (1-2æ—¥)**
1. âœ… scikit-learn ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
2. âœ… ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æ¨™æº–åŒ–
3. âœ… è¨­å®šæ¤œè¨¼å¼·åŒ–
4. âœ… åŸºæœ¬çš„ãªãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹è¿½åŠ 

### **Phase 2: å“è³ªå‘ä¸Š (1é€±é–“)**
1. â³ ä¸¦åˆ—å‡¦ç†å®Ÿè£…
2. â³ ãƒ¡ãƒ¢ãƒªåŠ¹ç‡æ”¹å–„
3. â³ ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½è¿½åŠ 
4. â³ åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ

### **Phase 3: é«˜åº¦ãªæ©Ÿèƒ½ (2-3é€±é–“)**
1. â³ ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
2. â³ è©³ç´°ç›£è¦–ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹
3. â³ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½
4. â³ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

## ğŸ¯ **æˆåŠŸæŒ‡æ¨™**

### **æŠ€è¡“æŒ‡æ¨™**
- **ã‚¨ãƒ©ãƒ¼ç‡**: < 1%
- **å¹³å‡å¿œç­”æ™‚é–“**: < 500ms
- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**: < 100MB (1000ä»¶æ¤œç´¢)
- **ä¸¦åˆ—å‡¦ç†åŠ¹ç‡**: 70%ä»¥ä¸Šã®é€Ÿåº¦å‘ä¸Š

### **å“è³ªæŒ‡æ¨™**
- **ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸**: > 90%
- **ã‚³ãƒ¼ãƒ‰å“è³ª**: Ruff ã‚¹ã‚³ã‚¢ A+
- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå®Œå…¨æ€§**: 100%

### **é‹ç”¨æŒ‡æ¨™**
- **ã‚·ã‚¹ãƒ†ãƒ å¯ç”¨æ€§**: > 99.9%
- **è¨­å®šã‚¨ãƒ©ãƒ¼ç‡**: < 0.1%
- **ãƒ¦ãƒ¼ã‚¶ãƒ¼æº€è¶³åº¦**: > 4.5/5.0

## ğŸ“ **çµè«–**

å®Ÿè£…ã—ãŸãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã¯**åŸºæœ¬çš„ã«é«˜å“è³ª**ã§å®Ÿç”¨å¯èƒ½ã§ã™ãŒã€ä»¥ä¸‹ã®æ”¹å–„ã«ã‚ˆã‚Šæ›´ãªã‚‹å“è³ªå‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™ï¼š

### **å³åº§ã«å¯¾å¿œ**
- ä¾å­˜é–¢ä¿‚ã®å®Œå…¨åŒ–
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®æ¨™æº–åŒ–
- è¨­å®šæ¤œè¨¼ã®å¼·åŒ–

### **ç¶™ç¶šçš„æ”¹å–„**
- ä¸¦åˆ—å‡¦ç†ã«ã‚ˆã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Š
- ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®æœ€é©åŒ–
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½ã®å¼·åŒ–

ã“ã‚Œã‚‰ã®æ”¹å–„ã«ã‚ˆã‚Šã€**ä¸–ç•Œã‚¯ãƒ©ã‚¹ã®æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ **ã¨ã—ã¦é•·æœŸçš„ã«é‹ç”¨å¯èƒ½ãªå“è³ªã‚’å®Ÿç¾ã§ãã¾ã™ã€‚

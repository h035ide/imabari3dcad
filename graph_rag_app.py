import os
import logging
import sys
from dotenv import load_dotenv

from llama_index.core import (
    SimpleDirectoryReader,
    KnowledgeGraphIndex,
    StorageContext
)
from llama_index.graph_stores.neo4j import Neo4jGraphStore
from llama_index.llms.openai import OpenAI
from langchain.tools import Tool
from llama_index.core.node_parser import MarkdownNodeParser

from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.memory import ConversationBufferWindowMemory

# --- 0. è¨­å®šã¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— ---

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# OpenAI APIã‚­ãƒ¼ã®ãƒã‚§ãƒƒã‚¯
if not os.getenv("OPENAI_API_KEY"):
    logging.error("OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    sys.exit(1)

# åŸºæœ¬çš„ãªãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(stream=sys.stdout, level=logging.INFO)
logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))

# --- 1. Neo4jã¸ã®æ¥ç¶šã¨GraphStoreã®å®šç¾© ---
# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ¥ç¶šæƒ…å ±ã‚’å–å¾—
logging.info("Neo4jãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶šã—ã¦ã„ã¾ã™...")
try:
    # ç’°å¢ƒå¤‰æ•°ã®å–å¾—ã¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®è¨­å®š
    neo4j_username = os.getenv("NEO4J_USERNAME", "neo4j")
    neo4j_password = os.getenv("NEO4J_PASSWORD")
    neo4j_uri = os.getenv("NEO4J_URI", "bolt://localhost:7687")
    neo4j_database = os.getenv("NEO4J_DATABASE", "neo4j")
    
    if not neo4j_password:
        logging.error("NEO4J_PASSWORDç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        sys.exit(1)
    
    graph_store = Neo4jGraphStore(
        username=neo4j_username,
        password=neo4j_password,
        url=neo4j_uri,
        database=neo4j_database,
    )
    storage_context = StorageContext.from_defaults(graph_store=graph_store)
    
    # æ—¢å­˜ã®ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆå¿…è¦ã«å¿œã˜ã¦ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã‚’è§£é™¤ï¼‰
    try:
        # Neo4jã®ã‚¯ã‚¨ãƒªã‚’ç›´æ¥å®Ÿè¡Œã—ã¦ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
        graph_store.query("MATCH (n) DETACH DELETE n")
        logging.info("æ—¢å­˜ã®ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚")
    except Exception as clear_error:
        logging.warning(f"ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªã‚¢ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒãªã„å¯èƒ½æ€§ï¼‰: {clear_error}")
except Exception as e:
    logging.error(f"Neo4jã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    logging.error(f"æ¥ç¶šæƒ…å ±: URI={neo4j_uri}, Database={neo4j_database}, Username={neo4j_username}")
    if hasattr(e, '__traceback__'):
        import traceback
        logging.error(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯: {traceback.format_exc()}")
    sys.exit(1)

# --- 2. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿ã¨çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰ ---
# ã“ã®å‡¦ç†ã¯ãƒªã‚½ãƒ¼ã‚¹ã‚’æ¶ˆè²»ã™ã‚‹ãŸã‚ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã®ã¿å®Ÿè¡Œã™ã‚‹ã®ãŒç†æƒ³çš„ã§ã™ã€‚
try:
    logging.info("`./data/api_doc/` ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
    documents = SimpleDirectoryReader("./data/api_doc/").load_data()

    logging.info("çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰ã—ã¦ã„ã¾ã™... ã“ã‚Œã«ã¯æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚")
    
    # 1. Markdownå¯¾å¿œã®Node Parserã‚’åˆæœŸåŒ–
    parser = MarkdownNodeParser()

    # 2. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è§£æã—ã¦ãƒãƒ¼ãƒ‰ï¼ˆãƒãƒ£ãƒ³ã‚¯ï¼‰ã«åˆ†å‰²
    nodes = parser.get_nodes_from_documents(documents)

    # çŸ¥è­˜æŠ½å‡ºã«ã¯é«˜ç²¾åº¦ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
    extraction_model = os.getenv("EXTRACTION_LLM_MODEL", "gpt-4.1")
    if not extraction_model:
        logging.error("EXTRACTION_LLM_MODELç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        sys.exit(1)
    extraction_llm = OpenAI(model=extraction_model, temperature=0.1)
    
    # çŸ¥è­˜æŠ½å‡ºç”¨ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å®šç¾©
    knowledge_extraction_prompt = """
    ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«é–¢é€£ã™ã‚‹çŸ¥è­˜ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
    
    æŠ½å‡ºã™ã‚‹çŸ¥è­˜ã¯ä»¥ä¸‹ã®å½¢å¼ã§è¡¨ç¾ã—ã¦ãã ã•ã„ï¼š
    - ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£é–“ã®é–¢ä¿‚ã¯æ˜ç¢ºã§å…·ä½“çš„ãªåå‰ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
    - ç©ºã®ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„
    - ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åã¯è‹±èªã§è¨˜è¿°ã—ã¦ãã ã•ã„
    
    ä¾‹ï¼š
    - "CreateVariable" HAS_PARAMETER "VariableName"
    - "CreateSketchPlane" RETURNS "SketchPlaneElement"
    - "PartObject" HAS_METHOD "CreateVariable"
    - "String" IS_TYPE_OF "Parameter"
    """
    
    index = KnowledgeGraphIndex(
        nodes, # <--- documentsã‹ã‚‰nodesã«å¤‰æ›´
        storage_context=storage_context,
        max_triplets_per_chunk=3,
        llm=extraction_llm,
        show_progress=True,
        include_embeddings=True,
        embed_kg_triplets=True,
        knowledge_extraction_prompt=knowledge_extraction_prompt,
    )
    logging.info("âœ… çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

except FileNotFoundError:
    logging.error("âŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª `./data/api_doc/` ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ä½œæˆã—ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
    sys.exit(1)
except Exception as e:
    logging.error(f"âŒ ã‚°ãƒ©ãƒ•æ§‹ç¯‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    logging.error(f"ã‚¨ãƒ©ãƒ¼ã®è©³ç´°: {type(e).__name__}")
    if hasattr(e, '__traceback__'):
        import traceback
        logging.error(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯: {traceback.format_exc()}")
    sys.exit(1)

# --- 3. ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½œæˆã—ã€LangChainãƒ„ãƒ¼ãƒ«ã¨ã—ã¦ãƒ©ãƒƒãƒ— ---
logging.info("ã‚°ãƒ©ãƒ•ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½œæˆã—ã¦ã„ã¾ã™...")
query_engine = index.as_query_engine(
    include_text=True,
    response_mode="tree_summarize",
    embedding_mode='hybrid',
    similarity_top_k=5,
)

# descriptionã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã„ã¤ã“ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã†ã¹ãã‹åˆ¤æ–­ã™ã‚‹ãŸã‚ã®é‡è¦ãªæŒ‡ç¤ºã§ã™ã€‚
def query_api_docs(query: str) -> str:
    """APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«é–¢ã™ã‚‹è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«"""
    try:
        response = query_engine.query(query)
        return str(response)
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

graph_rag_tool = Tool(
    name="APIDocumentationGraphRAGTool",
    description="APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«é–¢ã™ã‚‹è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«ä½¿ç”¨ã—ã¾ã™ã€‚ç‰¹ã«é–¢æ•°ã€ã‚¯ãƒ©ã‚¹ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é–“ã®é–¢ä¿‚æ€§ã‚’ç†è§£ã™ã‚‹ã®ã«å„ªã‚Œã¦ã„ã¾ã™ã€‚",
    func=query_api_docs
)

# --- 4. å¯¾è©±å‹ã®LangChainã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— ---
logging.info("å¯¾è©±ãƒ¡ãƒ¢ãƒªã‚’æŒã¤LangChainã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¦ã„ã¾ã™...")

# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè‡ªä½“ã«ã¯é«˜é€Ÿã§é«˜æ€§èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
agent_model = os.getenv("AGENT_LLM_MODEL", "gpt-4o")
if not agent_model:
    logging.error("âŒ AGENT_LLM_MODELç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    sys.exit(1)
agent_llm = ChatOpenAI(model=agent_model, temperature=0)
tools = [graph_rag_tool]

# ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¸ã®æœ€ã‚‚é‡è¦ãªæŒ‡ç¤ºæ›¸ã§ã™ã€‚
# å½¹å‰²ã€èƒ½åŠ›ã€æœŸå¾…ã•ã‚Œã‚‹æŒ¯ã‚‹èˆã„ã‚’æ—¥æœ¬èªã§æ˜ç¢ºã«å®šç¾©ã—ã¾ã™ã€‚
system_prompt = """
ã‚ãªãŸã¯å°‚é–€çš„ãªé–‹ç™ºè€…ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ã‚ãªãŸã®ä¸»ãªå½¹å‰²ã¯ã€éå…¬é–‹APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«é–¢ã™ã‚‹è³ªå•ã«ç­”ãˆã‚‹ã“ã¨ã§ã™ã€‚
å›ç­”ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã«ã¯ã€å¿…ãš `APIDocumentationGraphRAGTool` ã¨ã„ã†ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚

### æŒ‡ç¤º
- è³ªå•ã«ç­”ãˆã‚‹å‰ã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä½•ã‚’æ±‚ã‚ã¦ã„ã‚‹ã®ã‹ã€ãã—ã¦ãƒ„ãƒ¼ãƒ«ãŒã©ã®ã‚ˆã†ã«å½¹ç«‹ã¤ã‹ã‚’å¸¸ã«è€ƒãˆã¦ãã ã•ã„ã€‚
- APIã®å„è¦ç´ ãŒã©ã®ã‚ˆã†ã«é€£æºã—ã¦å‹•ä½œã™ã‚‹ã‹ã«ã¤ã„ã¦ã®è³ªå•ã«ã¯ã€ã“ã®ãƒ„ãƒ¼ãƒ«ãŒæœ€é©ã§ã™ã€‚
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¿½åŠ ã®è³ªå•ã‚’ã—ãŸå ´åˆã¯ã€ä¼šè©±ã®å±¥æ­´ã‚’ä½¿ç”¨ã—ã¦æ–‡è„ˆã‚’ç†è§£ã—ã¦ãã ã•ã„ã€‚
- ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦ã‚‚ç­”ãˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãã®æƒ…å ±ãŒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å­˜åœ¨ã—ãªã„ã“ã¨ã‚’æ˜ç¢ºã«ä¼ãˆã¦ãã ã•ã„ã€‚ç­”ãˆã‚’å‰µä½œã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚
- å›ç­”ã¯ç°¡æ½”ã‹ã¤æ­£ç¢ºã«ã—ã¦ãã ã•ã„ã€‚
- **å¿œç­”ã¯å¿…ãšæ—¥æœ¬èªã§è¡Œã£ã¦ãã ã•ã„ã€‚**
"""

prompt = ChatPromptTemplate.from_messages([
    ("system", system_prompt),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])

# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ãƒ¡ãƒ¢ãƒªã‚’è¿½åŠ ã—ã¾ã™ã€‚`k=5`ã¯ç›´è¿‘5å¾€å¾©ã®ä¼šè©±ã‚’è¨˜æ†¶ã™ã‚‹ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚
memory = ConversationBufferWindowMemory(
    memory_key='chat_history',
    k=5,
    return_messages=True
)

agent = create_openai_functions_agent(agent_llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True)

# --- 5. å¯¾è©±ãƒ«ãƒ¼ãƒ—ã®é–‹å§‹ ---
logging.info("âœ… ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸã€‚å¯¾è©±ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
print("\n--- APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ ---")
print("APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«é–¢ã™ã‚‹è³ªå•ã‚’ã©ã†ãã€‚ã€Œexitã€ã¾ãŸã¯ã€Œçµ‚äº†ã€ã¨å…¥åŠ›ã™ã‚‹ã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¾ã™ã€‚")

while True:
    try:
        user_input = input("\nğŸ‘¤ ã‚ãªãŸ: ")
        if user_input.lower() in ["exit", "quit", "çµ‚äº†"]:
            print("ğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: ã”åˆ©ç”¨ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚")
            break
        
        response = agent_executor.invoke({"input": user_input})
        print(f"ğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: {response['output']}")

    except KeyboardInterrupt:
        print("\nğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
        break
    except Exception as e:
        logging.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print("ğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")